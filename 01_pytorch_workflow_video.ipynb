{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRjQTa2ZjDNfdtISzf0coE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viv-bad/pytorch-course/blob/master/01_pytorch_workflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Workflow\n",
        "\n",
        "Let's explore an example PyTorch end to end workflow\n",
        "\n",
        "Resources:\n",
        "* Ground truth notebook: https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "* Book version of notebook: https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "* Ask a question: Github"
      ],
      "metadata": {
        "id": "vkC0-AMuYgOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering = {1: \"data (prepare and load)\", 2: \"build model\", 3: \"fitting the model to data (training)\", 4: \"making predictions and evaluating a model (inference)\", 5: \"saving and loading a model\", 6: \"putting it all together\"}\n",
        "what_were_covering"
      ],
      "metadata": {
        "id": "-n12NvlbZhYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "SfSrEqRMZ0ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data (preparing and loading)\n",
        "\n",
        "Data can be almost anything in ML:\n",
        "\n",
        "* Excel spreadsheet\n",
        "* Images\n",
        "* Videos\n",
        "* Audio\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "1. Get data into numerical representation (in tensors)\n",
        "2. Build a model to learn patterns in that numerical representation\n",
        "\n",
        "To showcase this, let's create some *known* data using the linear regression formula\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with *known* **parameters**. A parameter is something that a model learns.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D7_Gu8BGacjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create *known* parameters\n",
        "\n",
        "weight = 0.7 # m in y = mx + b\n",
        "bias = 0.3 # c in y = mx + b\n",
        "\n",
        "# Create\n",
        "\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim = 1) #X is a matrix or tensor, and a capiutal X represents a tensor, lower case = vector, input numbers\n",
        "y = weight * X + bias # output numbers\n",
        "\n",
        "X[:10], y[:10], len(X), len(y) # learn the representation of the input and how it maps to the output\n",
        "\n"
      ],
      "metadata": {
        "id": "dHZb2uZEaxtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets (very important in machine learning)\n",
        "\n",
        "* Training - 60 - 80%\n",
        "* Validation - 10 - 20% - often used but not always\n",
        "* Test - 10 - 20%\n",
        "\n",
        "Let's create a training and test set with our data.\n",
        "\n"
      ],
      "metadata": {
        "id": "kvaNDiP-axyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train/test split\n",
        "train_split = int(0.8 * len(X))\n",
        "train_split # these samples are used to train the model, and we will then use the rest to test\n",
        "\n",
        "X_train, y_train = X[:train_split], y[:train_split] #index up until the train split index\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "tJ4WDgVnax15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How might we better visualise our data?\n"
      ],
      "metadata": {
        "id": "MtKoItBSax4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  #Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # plot predictions if exist\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  plt.legend(prop={\"size\": 14})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lUu_NjmdfoYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "id": "K7ajvSxfax7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build model\n",
        "\n",
        "Our first PyTorch Model\n",
        "\n",
        "What our model does:\n",
        "* Starts with random values for weight and bias\n",
        "* Looks at training data and adjusts the random values to better represent (or get closer to) the ideal values (the weight and bias values to used to create the data)\n",
        "\n",
        "How does it do so?\n",
        "Through two main algorithms:\n",
        "1. Gradient descent - set by requires_grad=True\n",
        "2. Back propogation\n",
        "\n",
        "\n",
        "\n",
        "Learning Process\n",
        "\n",
        "The model starts with random or pre-initialized weights and biases\n",
        "During training, it adjusts these values incrementally to minimize prediction errors\n",
        "This adjustment happens through algorithms like gradient descent\n",
        "The goal is to find weight and bias values that make the model fit the training data well\n"
      ],
      "metadata": {
        "id": "yMNuWycsax9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "# Create linear regression model class\n",
        "\n",
        "class LinearRegressionModel(nn.Module): #Almost everything in PyTorch inherits from nn.Module\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float)) # start with random numbers, look at training data, and update those random numbers to represent the pattern in the training data, same for bias\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "    #Forward method to define the computation in the model\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: #x is the input training data\n",
        "      return self.weight * x + self.bias # This is the linear regression formula\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UV62I93ZhR0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all building blocks for computation graphs (a neural network can be considered a computational graph)\n",
        "* torch.nn.Parameter - what paremeters should our model try and learn, often a PyTorch layer from torch.nn will set these for us\n",
        "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
        "* torch.optim - this is where the optimisers live which help with gradient descent\n",
        "* def forward() - All nn.Module subclasses require you to overwrite forward(), this is run to run the computation\n",
        "\n",
        "Cheat sheet - https://pytorch.org/tutorials/beginner/ptcheat.html"
      ],
      "metadata": {
        "id": "7SUsQQrnkf0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the contents of our PyTorch model\n",
        "\n",
        "Now we've created a model let's see what's inside...\n",
        "\n",
        "We can check out our model parameters or whats inside our model using `.parameters()`"
      ],
      "metadata": {
        "id": "3VB20Joskf-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module)\n",
        "\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# Check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "QAC1TgZYkgB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters - we want to write code now, that will get these values closer to the set weight and bias from earlier (0.7, 0.3) using the data, gradient descent and back propogration.\n",
        "# Usually you won't know what the ideal values for weight and bias are. we do here as a test\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "cxVsVLsGkgJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making predictions using `torch.inference_mode()`\n",
        "\n",
        "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.\n",
        "\n",
        "When we pass data through our model, it's going to run it through the `forward` method.\n"
      ],
      "metadata": {
        "id": "M44EungTqNAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make  predictions with model\n",
        "with torch.inference_mode(): #during inference, we dont do training, so we don't need gradient descent, so it is turned off here, this means pytorch behind the scenes is keeping track of less data, gives faster predictions\n",
        "  y_preds = model_0(X_test) #pass X_test data through model forward method\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "bf8DvPjmu2IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds) # because we are initialized with random weight and bias, the initial prediction is bad, and this is where we now write some code to get these predictions closer"
      ],
      "metadata": {
        "id": "1PbtsqK0vDXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Train model\n",
        "\n",
        "The whole idea of training is for a model to move from some *unknown* parameters (these may be random), to some known parameters.\n",
        "\n",
        "From a poor representation of the data to a better representation of the data.\n",
        "\n",
        "One way to measure how poorly our model's prediction is, is to use a loss function.\n",
        "\n",
        "Note: Loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
        "\n",
        "* **Loss function: ** A function to measure how wrong your models predictions are to the ideal outputs. Lower is better.\n",
        "\n",
        "Mean absolute error, mean squared error\n",
        "\n",
        "* **Optimiser: ** Takes into account the loss of the model and adjusts the model's parameters (e.g. weight and bias, in our case) to improve the loss function\n",
        "\n",
        "And specifically for PyTorch we need:\n",
        "\n",
        "* A training loop\n",
        "* A testing loop\n",
        "\n"
      ],
      "metadata": {
        "id": "0Sk1jL1kvbSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's parameters (a parameter is a value that the model sets itself)\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "ODSOYbK-zmx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Set up an optimiser (stochastic gradient descent) - increases or decreases the weight and bias to reduce loss\n",
        "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.01) #lr = learning rate, very important hyperparameter (value that we set ourselves), the higher the lr, the more it adjusts the parameters in one hit\n"
      ],
      "metadata": {
        "id": "8Czucsi7xP_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a training loop (and testing loop) in Pytorch\n",
        "\n",
        "A couple things we need in a training loop:\n",
        "\n",
        "0. Loop through the data\n",
        "1. Forward pass (this involves data moving through our model's `forward()` functions) to make predictions on data - also called forward propogration\n",
        "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**backpropogration**)\n",
        "5. Optimizer step - use the optimizer to adjust out model's parameters to try to improve the loss (**gradient descent**).\n",
        "\n"
      ],
      "metadata": {
        "id": "en8KkzGUznKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "2Gs5q1DLFGwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# An epoch is one loop through the data... (hyperparameter)\n",
        "epochs = 200\n",
        "\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "\n",
        "### Training\n",
        "# 0. Loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_0.forward(X_train) # learn patterns on training data to then eval model on test data\n",
        "\n",
        "  # 2. Calculate the loss - MAE - difference between models predictions on training data set and ideal training values\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  print(f\"loss: {loss}\")\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropogation on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer (perform the gradient descent)\n",
        "  optimizer.step() # by default, how the optimizer changes will accumulate through the loop, so we have to zero them above in step 3 for the next iteration of the loop\n",
        "\n",
        "  ### Testing - this turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
        "\n",
        "  model_0.eval() # turns off gradient tracking\n",
        "  with torch.inference_mode(): #turns off gradient tracking and more behind the scenes - don't need to do learning here when testing\n",
        "    # 1. do forward pass\n",
        "    test_pred = model_0(X_test) # now that the model has been optimised/trained above, we now want to test/evaluate the model with the test data, to get test predictions and test loss\n",
        "    # 2. calculate the loss with test data\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch:  {epoch} | Loss: {loss} | test loss: {test_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "    # print out model state_dict\n",
        "    print(model_0.state_dict())\n"
      ],
      "metadata": {
        "id": "5h5Df3J6FGtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "\n",
        "epoch_count, loss_values, test_loss_values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WXWCT535U-za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values).numpy()), label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "8d9n8rSM4PMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds_new = model_0(X_test)"
      ],
      "metadata": {
        "id": "_R4OD2ItFG0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "id": "MWQ6ArBITAzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds_new)"
      ],
      "metadata": {
        "id": "lGCWjjZdTrGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving a model in PyTorch\n",
        "\n",
        "There are three main methods you should know about for saving and loading models in PyTorch:\n",
        "\n",
        "1. `torch.save()` - allows you to save a PyTorch object in Python's pickle format.\n",
        "2. `torch.load()` - allows you to load a saved PyTorch object.\n",
        "3. `torch.nn.Module.load_state_dict()` - this allows you to load a model's saves state dictionary.\n"
      ],
      "metadata": {
        "id": "Lac-TS2dTokT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict() # model params are stored here in a Python dictionary. Here we only have two params, but in the future you could be working with a model with millions of parameters."
      ],
      "metadata": {
        "id": "YzfEfdTx6b_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create a model save path\n",
        "MODEL_NAME = \"01_pytorch_orkflow_model_0.pth\" #pytorch objects usually saved in .pth or .pt\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "MODEL_SAVE_PATH\n",
        "\n",
        "# 3. Save model state_dict()\n",
        "print(f\"Saving model to {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "KNOj5-Fk6IDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading a PyTorch model, this creates a new instance of the model class and loads the state dict into that\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "# Load saves state_dict\n",
        "print(f\"Loading model from {MODEL_SAVE_PATH}\")\n",
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
      ],
      "metadata": {
        "id": "8akw42BA6ILe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "id": "udvv73pS6IOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "y_preds"
      ],
      "metadata": {
        "id": "4-1i_bvg93UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with the loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "id": "j9XlKMaJ6IRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds == loaded_model_preds"
      ],
      "metadata": {
        "id": "A_DFNpKO91w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Putting it all together\n",
        "\n",
        "Let's go back through the steps above and see it all in one place."
      ],
      "metadata": {
        "id": "FcLvVeli959_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "G-4SSv13-evA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create device agnostic code to switch between CPU and GPU"
      ],
      "metadata": {
        "id": "M2YXQSJI-e9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "J4pIdVgx-fAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Data\n"
      ],
      "metadata": {
        "id": "LcZdLhS0-fDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some data using the linear regression formula y = mx + c, or y = weight * X + bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create range values\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y (features and labels)\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1) # unsqueeze to add another dimension\n",
        "y = weight * X + bias\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "id": "du9ill5Y_y30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "lk2ZWqqm-fGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data\n",
        "plot_predictions(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "MNJCVMyv-fJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Building a PyTorch linear model"
      ],
      "metadata": {
        "id": "xzc8O8KbAtMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.weight = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    # self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    # Use nn.Linear() for creating the model parameters instead this time\n",
        "    self.linear_layer = nn.Linear(in_features=1, out_features=1) # input and output features - highly dependent on the data shape you work with in X_train and y_train\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_1 = LinearRegressionModelV2()\n",
        "model_1, model_1.state_dict()"
      ],
      "metadata": {
        "id": "rlKiWz1kAtP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "eY9H5jkqAtSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Training\n",
        "For training we need:\n",
        "\n",
        "* Loss function\n",
        "* Optimizer\n",
        "* Training loop\n",
        "* Testing loop\n"
      ],
      "metadata": {
        "id": "uR34fwCaAtU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up loss function\n",
        "loss_fn = nn.L1Loss() # same as MAE\n",
        "\n",
        "#Optimizer\n",
        "\n",
        "optimizer = torch.optim.SGD(params = model_1.parameters(),lr = 0.01)\n",
        "\n"
      ],
      "metadata": {
        "id": "EnX8iKG7DEgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "\n",
        "  # Forward pass\n",
        "  y_pred = model_1(X_train) # data will go through linear layer\n",
        "\n",
        "  # loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # optimizer zero grad\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #Backpropogration\n",
        "  loss.backward()\n",
        "\n",
        "  # optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(X_test)\n",
        "    test_loss= loss_fn(test_pred, y_test)\n",
        "\n",
        "  # print\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | test loss: {test_loss}\")"
      ],
      "metadata": {
        "id": "xIGMBiRKDUWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "kt1Sg5IAAtXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4 Making and evaluating predictions"
      ],
      "metadata": {
        "id": "Eo1yH7JTAtag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_1(X_test)\n",
        "y_preds"
      ],
      "metadata": {
        "id": "6spHToDuEXIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "id": "1PnNQ9shAtdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9LwcLw_FAtgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rY0SzFzcAtiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0TPEQESbAtlc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}